{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcbfc36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished after 20 steps\n",
      "Episode 2 finished after 28 steps\n",
      "Episode 3 finished after 14 steps\n",
      "Episode 4 finished after 11 steps\n",
      "Episode 5 finished after 49 steps\n",
      "Episode 6 finished after 11 steps\n",
      "Episode 7 finished after 9 steps\n",
      "Episode 8 finished after 35 steps\n",
      "Episode 9 finished after 40 steps\n",
      "Episode 10 finished after 44 steps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# 创建CartPole环境\n",
    "env = gym.make('CartPole-v1', render_mode=\"human\")\n",
    "\n",
    "# 进行若干次实验\n",
    "for episode in range(10):\n",
    "    state = env.reset()\n",
    "    terminated = False\n",
    "    step_count = 0\n",
    "\n",
    "    # 在每次实验中，执行若干步操作\n",
    "    while not terminated:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        step_count += 1\n",
    "\n",
    "    print(f\"Episode {episode + 1} finished after {step_count} steps\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ac7f0",
   "metadata": {},
   "source": [
    "测试Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd99bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward: 295.3\n",
      "Total reward: 300.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "def run_episode(env, parameters):\n",
    "    observation = env.reset()[0]\n",
    "    total_reward = 0\n",
    "    for _ in range(300):\n",
    "        action = 0 if np.matmul(parameters, observation) < 0 else 1\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        if terminated:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def train():\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    best_params = None\n",
    "    best_reward = 0\n",
    "    noise_scaling = 0.1\n",
    "    episodes_per_update = 10\n",
    "\n",
    "    for _ in range(10000):\n",
    "        parameters = best_params if best_params is not None else np.random.rand(4) * 2 - 1\n",
    "        parameters += (np.random.rand(4) * 2 - 1) * noise_scaling\n",
    "        reward_sum = 0\n",
    "        for _ in range(episodes_per_update):\n",
    "            reward_sum += run_episode(env, parameters)\n",
    "        \n",
    "        average_reward = reward_sum / episodes_per_update\n",
    "        if average_reward > best_reward:\n",
    "            best_reward = average_reward\n",
    "            best_params = parameters\n",
    "            if average_reward >= 290.0:\n",
    "                print(f\"average reward: {average_reward}\")\n",
    "                break\n",
    "\n",
    "    return best_params\n",
    "\n",
    "best_parameters = train()\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "total_reward = run_episode(env, best_parameters)\n",
    "print(f\"Total reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07473a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 206.0 [ 0.70975396 -0.30061841  0.72104549  1.16557572 -0.00898724]\n",
      "(206.0, array([ 0.70975396, -0.30061841,  0.72104549,  1.16557572, -0.00898724]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time\n",
    "\n",
    "def get_action(weights, observation):# 根据权值对当前状态做出决策\n",
    "    wxb = np.dot(weights[:4], observation) + weights[4] # 计算加权和\n",
    "    if wxb >= 0:# 加权和大于0时选取动作1，否则选取0\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_sum_reward_by_weights(env, weights):\n",
    "# 测试不同权值的控制模型有效控制的持续时间（或奖励）\n",
    "    observation = env.reset()[0] # 重置初始状态\n",
    "    sum_reward = 0 # 记录总的奖励\n",
    "    for t in range(1000):\n",
    "        # time.sleep(0.01)\n",
    "        # env.render()\n",
    "        action = get_action(weights, observation) # 获取当前权值下的决策动作\n",
    "        observation, reward, terminated, truncated, info = env.step(action)# 执行动作并获取这一动作下的下一时间步长状态\n",
    "        sum_reward += reward\n",
    "        # print(sum_reward, action, observation, reward, done, info)\n",
    "        if terminated:# 如若游戏结束，返回\n",
    "            break\n",
    "    return sum_reward\n",
    "\n",
    "\n",
    "def get_weights_by_random_guess():\n",
    "# 选取随机猜测的5个随机权值\n",
    "    return np.random.rand(5)\n",
    "\n",
    "def get_weights_by_hill_climbing(best_weights):\n",
    "# 通过爬山算法选取权值（在当前最好权值上加入随机值）\n",
    "    return best_weights + np.random.normal(0, 0.1, 5)\n",
    "\n",
    "def get_best_result(algo=\"random_guess\"):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    np.random.seed(10)\n",
    "    best_reward = 0 # 初始最佳奖励\n",
    "    best_weights = np.random.rand(5) # 初始权值为随机取值\n",
    "\n",
    "    for iter in range(10000):# 迭代10000次\n",
    "        cur_weights = None\n",
    "\n",
    "        if algo == \"hill_climbing\": # 选取动作决策的算法 \n",
    "            # print(best_weights)\n",
    "            cur_weights = get_weights_by_hill_climbing(best_weights)\n",
    "        else: # 若为随机猜测算法，则选取随机权值\n",
    "            cur_weights = get_weights_by_random_guess()\n",
    "        # 获取当前权值的模型控制的奖励和\n",
    "        cur_sum_reward = get_sum_reward_by_weights(env, cur_weights)\n",
    "\n",
    "        # print(cur_sum_reward, cur_weights)\n",
    "        # 更新当前最优权值\n",
    "        if cur_sum_reward > best_reward:\n",
    "            best_reward = cur_sum_reward\n",
    "            best_weights = cur_weights\n",
    "        # 达到最佳奖励阈值后结束\n",
    "        if best_reward >= 200:\n",
    "            break\n",
    "\n",
    "    print(iter, best_reward, best_weights)\n",
    "    return best_reward, best_weights\n",
    "\n",
    "# 程序从这里开始执行\n",
    "print(get_best_result(\"hill_climbing\")) # 调用爬山算法寻优并输出结果 \n",
    "\n",
    "# env = gym.make(\"CartPole-v0\")\n",
    "# get_sum_reward_by_weights(env, [0.22479665, 0.19806286, 0.76053071, 0.16911084, 0.08833981])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8110af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
